{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file is already unzipped\n"
     ]
    }
   ],
   "source": [
    "# if it is unzipped, unzip kagglecatsanddogs_5340.zip\n",
    "if not os.path.exists('PetImages') and not os.path.exists('images'):\n",
    "    # unzip kagglecatsanddogs_5340.zip\n",
    "    print(\"The file is not unzipped, unzipping it now\")\n",
    "    with zipfile.ZipFile(\"kagglecatsanddogs_5340.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    # delete unnecessary files\n",
    "    os.remove(\"CDLA-Permissive-2.0.pdf\")\n",
    "    os.remove(\"readme[1].txt\")\n",
    "else:\n",
    "    print(\"The file is already unzipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images folder already exists\n"
     ]
    }
   ],
   "source": [
    "# rename the images as img_0.jpg, img_1.jpg, etc. and save the labels in a pandas dataframe where 0 is cat and 1 is dog\n",
    "# there is ID and label in the dataframe\n",
    "# the labels are 0 for cat and 1 for dog\n",
    "# images folder should be in the same directory as this file\n",
    "\n",
    "if not os.path.exists('images'):\n",
    "    print(\"Creating images folder and labels dataframe\")\n",
    "    os.makedirs('images')\n",
    "    os.makedirs('other_images')\n",
    "    os.makedirs('val_images')\n",
    "    other_images_split = 0.1\n",
    "    val_images_split = 0.1\n",
    "    other_images_count = 0\n",
    "    labels = pd.DataFrame(columns=['ID', 'label'])\n",
    "    val_labels = pd.DataFrame(columns=['ID', 'label'])\n",
    "    count = 0\n",
    "    corrupted_count = 0\n",
    "    val_count = 0\n",
    "    for folder in ['Cat', 'Dog']:\n",
    "        for i, file in enumerate(os.listdir('PetImages/'+folder)):\n",
    "            # choose randomly with other_images_split percent of the images to be in the other_images folder\n",
    "            if np.random.rand() < other_images_split:\n",
    "                try:\n",
    "                    img_array = cv.imread('PetImages/'+folder+'/'+file)\n",
    "                    otherImage = cv.resize(img_array, (256, 256), interpolation=cv.INTER_AREA)\n",
    "                    os.rename('PetImages/'+folder+'/'+file, 'other_images/img_'+str(other_images_count)+'.jpg')\n",
    "                    other_images_count += 1\n",
    "                except Exception as e:\n",
    "                    corrupted_count += 1\n",
    "                    print(e)\n",
    "                    print('Deleting ', 'PetImages/'+folder+'/'+file)\n",
    "                    os.remove('PetImages/'+folder+'/'+file)\n",
    "            elif np.random.rand() < val_images_split:\n",
    "                try:\n",
    "                    img_array = cv.imread('PetImages/'+folder+'/'+file)\n",
    "                    otherImage = cv.resize(img_array, (256, 256), interpolation=cv.INTER_AREA)\n",
    "                    os.rename('PetImages/'+folder+'/'+file, 'val_images/img_'+str(val_count)+'.jpg')\n",
    "                    val_labels.loc[val_count] = [val_count, 0 if folder == 'Cat' else 1]\n",
    "                    val_count += 1\n",
    "                except Exception as e:\n",
    "                    corrupted_count += 1\n",
    "                    print(e)\n",
    "                    print('Deleting ', 'PetImages/'+folder+'/'+file)\n",
    "                    os.remove('PetImages/'+folder+'/'+file)\n",
    "            else:\n",
    "                try:\n",
    "                    img_array = cv.imread('PetImages/'+folder+'/'+file)\n",
    "                    otherImage = cv.resize(img_array, (256, 256), interpolation=cv.INTER_AREA)\n",
    "                    os.rename('PetImages/'+folder+'/'+file, 'images/img_'+str(count)+'.jpg')\n",
    "                    labels.loc[count] = [count, 0 if folder == 'Cat' else 1]\n",
    "                    count += 1\n",
    "                except Exception as e:\n",
    "                    corrupted_count += 1\n",
    "                    print(e)\n",
    "                    print('Deleting ', 'PetImages/'+folder+'/'+file)\n",
    "                    os.remove('PetImages/'+folder+'/'+file)\n",
    "    # delete the PetImages folder\n",
    "    if os.path.exists('PetImages'):\n",
    "        if os.path.exists('PetImages/Cat'):\n",
    "            os.rmdir('PetImages/Cat')\n",
    "        if os.path.exists('PetImages/Dog'):\n",
    "            os.rmdir('PetImages/Dog')\n",
    "        os.rmdir('PetImages')\n",
    "    #  save the labels dataframe as a csv file\n",
    "    labels.to_csv('labels.csv')\n",
    "    val_labels.to_csv('val_labels.csv')\n",
    "    print(\"Number of corrupted images: \", corrupted_count)\n",
    "else:\n",
    "    print(\"images folder already exists\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining dataset class\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "      'Characterizes a dataset for PyTorch'\n",
    "      def __init__(self, image_dir, label_dir, transform=None):\n",
    "            'Initialization'\n",
    "            self.image_dir = image_dir\n",
    "            self.label_dir = label_dir\n",
    "            self.transform = transform\n",
    "\n",
    "            self.labels = pd.read_csv(label_dir)\n",
    "            self.images = []\n",
    "            # go through the images folder and add the names of the images to the images list with the order\n",
    "            for i, file in enumerate(os.listdir(image_dir)):\n",
    "                  self.images.append(f\"img_{str(i)}.jpg\")\n",
    "            # Note: store the directory of the images instead of the images themselves\n",
    "\n",
    "\n",
    "      def __len__(self):\n",
    "            # return the number of samples\n",
    "            return len(self.labels)\n",
    "\n",
    "      def __getitem__(self, index):\n",
    "            'Generates one sample of data'\n",
    "            img_dir = self.images[index]\n",
    "            img = cv.imread(self.image_dir + '/' + img_dir)\n",
    "            if self.transform:\n",
    "                  img = self.transform(img)\n",
    "            label = self.labels.loc[self.labels['ID'] == index, 'label'].item()\n",
    "            return img, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# we are using AlexNet model with 2 classes\n",
    "# we are defining the model from scratch\n",
    "\n",
    "class AlexNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout_prob=0.5):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes),\n",
    "            nn.Softmax(dim=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define the forward pass\n",
    "        z = self.layer1(x)\n",
    "        z = self.layer2(z)\n",
    "        z = self.layer3(z)\n",
    "        z = self.layer4(z) \n",
    "        z = self.layer5(z)\n",
    "        z = z.reshape(z.size(0), -1)\n",
    "        z = self.fc(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.fc2(z)\n",
    "        return z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda\n",
      "GPU Name: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "Total GPU Memory: 4.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Current device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define hyperparameters\n",
    "leanring_rate = 0.001\n",
    "epochs = 10\n",
    "dropout_prob = 0.5\n",
    "num_classes = 2\n",
    "batch_size = 5\n",
    "weight_decay = 0.0001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train dataset and dataloader\n",
    "\n",
    "# define the transformation where the the image is read from the directory, resized to 256x256, normalized and converted to a tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "train_dataset = Dataset(image_dir='images', label_dir='labels.csv', transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "val_dataset = Dataset(image_dir='val_images', label_dir='val_labels.csv', transform=transform)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test the train and val dataloader\n",
    "\n",
    "# # get a batch of images and labels and plot the images and show their labels\n",
    "# # test the train dataloader\n",
    "# train_images, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "# # test the validation dataloader\n",
    "# val_images, val_labels = next(iter(val_dataloader))\n",
    "\n",
    "# # plot a batch of train and val images with their labels. First row is train and second row is val\n",
    "# fig, ax = plt.subplots(2, 5)\n",
    "# for i in range(5):\n",
    "#     train_img = train_images[i].permute(1, 2, 0)\n",
    "#     train_img = train_img * 0.5 + 0.5    # un normalize the image\n",
    "#     ax[0, i].imshow(train_img)\n",
    "#     ax[0, i].set_title(\"Cat\" if train_labels[i] == 0 else \"Dog\")\n",
    "#     ax[0, i].axis('off')\n",
    "#     val_img = val_images[i].permute(1, 2, 0)\n",
    "#     val_img = val_img * 0.5 + 0.5    # un normalize the image\n",
    "#     ax[1, i].imshow(val_img)\n",
    "#     ax[1, i].set_title(\"Cat\" if val_labels[i] == 0 else \"Dog\")\n",
    "#     ax[1, i].axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the loss function and optimizer\n",
    "\n",
    "# define the model\n",
    "myModel = AlexNet(num_classes=num_classes, dropout_prob=dropout_prob).to(device)\n",
    "\n",
    "# define the loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(myModel.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4241, 0.5759],\n",
      "        [0.4227, 0.5773],\n",
      "        [0.5917, 0.4083],\n",
      "        [0.3559, 0.6441],\n",
      "        [0.2347, 0.7653]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([5, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NSagi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# try the forward pass using the train dataloader\n",
    "\n",
    "myModel = AlexNet()\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "result1 = myModel.forward(images)\n",
    "\n",
    "print(result1)\n",
    "print(result1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model\n",
    "# remember to one hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
